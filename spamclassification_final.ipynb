{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80a25488",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30106c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('spam.csv',encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0eefcd50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1                                                 v2 Unnamed: 2  \\\n",
       "0   ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
       "1   ham                      Ok lar... Joking wif u oni...        NaN   \n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
       "3   ham  U dun say so early hor... U c already then say...        NaN   \n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
       "\n",
       "  Unnamed: 3 Unnamed: 4  \n",
       "0        NaN        NaN  \n",
       "1        NaN        NaN  \n",
       "2        NaN        NaN  \n",
       "3        NaN        NaN  \n",
       "4        NaN        NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8f0e2ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 5)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2002a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Data cleaning\n",
    "# 2. EDA\n",
    "# 3. Text Preprocessing\n",
    "# 4. Model building\n",
    "# 5. Evaluation\n",
    "# 6. Improvement\n",
    "# 7. Website\n",
    "# 8. Deploy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e1ca6e",
   "metadata": {},
   "source": [
    "## Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dea7057d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5572 entries, 0 to 5571\n",
      "Data columns (total 5 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   v1          5572 non-null   object\n",
      " 1   v2          5572 non-null   object\n",
      " 2   Unnamed: 2  50 non-null     object\n",
      " 3   Unnamed: 3  12 non-null     object\n",
      " 4   Unnamed: 4  6 non-null      object\n",
      "dtypes: object(5)\n",
      "memory usage: 217.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da4afe51",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['Unnamed: 2','Unnamed: 3','Unnamed: 4'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "117fc91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'v1':'label','v2':'text'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a4214d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012</th>\n",
       "      <td>ham</td>\n",
       "      <td>Beautiful Truth against Gravity.. Read careful...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3175</th>\n",
       "      <td>ham</td>\n",
       "      <td>Havent still waitin as usual... ÌÏ come back s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2158</th>\n",
       "      <td>ham</td>\n",
       "      <td>I think you should go the honesty road. Call t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1037</th>\n",
       "      <td>ham</td>\n",
       "      <td>naughty little thought: 'its better to flirt, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4972</th>\n",
       "      <td>ham</td>\n",
       "      <td>Oops I was in the shower when u called. Hey a ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                               text\n",
       "2012   ham  Beautiful Truth against Gravity.. Read careful...\n",
       "3175   ham  Havent still waitin as usual... ÌÏ come back s...\n",
       "2158   ham  I think you should go the honesty road. Call t...\n",
       "1037   ham  naughty little thought: 'its better to flirt, ...\n",
       "4972   ham  Oops I was in the shower when u called. Hey a ..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "837f8d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "lb=LabelEncoder()\n",
    "df['label']=lb.fit_transform(df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "622ff6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop duplicates value\n",
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c6a7fa25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data pre processing\n",
    "# lower case\n",
    "#tokenization\n",
    "#removing of special chracter\n",
    "# removing of stop words and punction\n",
    "#stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5e8c0fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lower the text\n",
    "df['text']  = df['text'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "04172f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#removal of html tags\n",
    "import re\n",
    "def remove_html_tags(data):\n",
    "    pattern = re.compile('<.*?>')\n",
    "    return pattern.sub(r'', data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "86a64705",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"<html><body><p> Movie 1</p><p> Actor - Aamir Khan</p><p> Click here to <a href='http://google.com'>download</a></p></body></html>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "87add506",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Movie 1 Actor - Aamir Khan Click here to download'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_html_tags(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8c972118",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].apply(lambda x: remove_html_tags(x)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "50b1b44e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'go until jurong point, crazy.. available only in bugis n great world la e buffet... cine there got amore wat...'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e33c493d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading stopwords: <urlopen error [Errno 11001]\n",
      "[nltk_data]     getaddrinfo failed>\n"
     ]
    }
   ],
   "source": [
    "#remove stop words \n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "sw_lsit = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ca1173df",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].apply(lambda x: [item for item in x.split() if item not in sw_lsit]).apply(lambda x:\" \".join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cec3418b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'go jurong point, crazy.. available bugis n great world la e buffet... cine got amore wat...'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6437c006",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# word tokenization k lya yah download krna zrori hoti ha\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "04648bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove the punctions and alpha numeric\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def remove_punct_alphanumeric(text):\n",
    "    # Tokenize the text\n",
    "    tokens = word_tokenize(text)\n",
    "    # Filter out punctuation and alphanumeric tokens\n",
    "    cleaned_tokens = [word for word in tokens if word.isalpha()]\n",
    "    # Join tokens back to a single string\n",
    "    return \" \".join(cleaned_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6fea8728",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].apply(lambda x: remove_punct_alphanumeric(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "561d0c76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'go jurong point crazy available bugis n great world la e buffet cine got amore wat'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4a15753f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e8b6ad58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9100dacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_text = df['text'].apply(word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1862408f",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_model = Word2Vec( window=5, min_count=2, sorted_vocab=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9d93829f",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_model.build_vocab(tokenized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "35f1013d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(376442, 454610)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_model.train(tokenized_text, total_examples=len(tokenized_text), epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ac04b559",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('mobile', 0.9966954588890076),\n",
       " ('camcorder', 0.9958181977272034),\n",
       " ('nokia', 0.9927514791488647),\n",
       " ('call', 0.9907126426696777),\n",
       " ('txt', 0.9900854229927063),\n",
       " ('reply', 0.9890351295471191),\n",
       " ('urgent', 0.9867748022079468),\n",
       " ('awarded', 0.9861122369766235),\n",
       " ('bonus', 0.9838712811470032),\n",
       " ('caller', 0.9833742380142212)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_model.wv.most_similar('free')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e3b26adc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.07717932,  0.13817424,  0.01980715, ..., -0.12675694,\n",
       "         0.07149473, -0.01175104],\n",
       "       [-0.07868521,  0.1451806 ,  0.00268184, ..., -0.13861053,\n",
       "         0.05760023, -0.0028626 ],\n",
       "       [-0.06277093,  0.10062246, -0.04851905, ..., -0.03144937,\n",
       "         0.06673976, -0.04043418],\n",
       "       ...,\n",
       "       [-0.08459446,  0.12437933,  0.00636146, ..., -0.1057489 ,\n",
       "         0.0360407 , -0.00572099],\n",
       "       [-0.09371207,  0.13587268, -0.00604754, ..., -0.13311465,\n",
       "         0.0539788 , -0.02461235],\n",
       "       [ 0.01195649,  0.1801031 , -0.06017263, ..., -0.17108291,\n",
       "         0.02745568,  0.03434882]], dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_model.wv.get_normed_vectors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fa4dfa93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Generate Average Embedding for Each Document\n",
    "def document_vector(doc):\n",
    "    # Filter out words not in the model vocabulary\n",
    "    doc = [word for word in doc if word in word2vec_model.wv]\n",
    "    # Return the average of word vectors for words in the document\n",
    "    return np.mean(word2vec_model.wv[doc], axis=0) if doc else np.zeros(word2vec_model.vector_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bce74ebb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'go jurong point crazy available bugis n great world la e buffet cine got amore wat'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d5c0cefa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['vector'] = df['text'].apply(lambda x: document_vector(word_tokenize(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "58d1d6f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.19312821,  0.34967312,  0.00156326,  0.05803084,  0.02221723,\n",
       "       -0.55361015,  0.01770016,  0.6452265 , -0.24848506, -0.1365827 ,\n",
       "       -0.07524671, -0.4936824 , -0.09975356,  0.22425131,  0.0799759 ,\n",
       "       -0.20962784,  0.08364524, -0.3834261 , -0.02499807, -0.6342934 ,\n",
       "        0.22141005,  0.07646465,  0.169377  , -0.10779257, -0.17806569,\n",
       "        0.03337314, -0.2848181 , -0.23494625, -0.31284165,  0.0644025 ,\n",
       "        0.35615495,  0.10046743,  0.22058637, -0.21175675, -0.16047491,\n",
       "        0.31492043,  0.0328128 , -0.2610713 , -0.19873162, -0.59968835,\n",
       "       -0.00135402, -0.3158462 , -0.03056359, -0.08386309,  0.25837964,\n",
       "       -0.07437836, -0.32562682, -0.07913299,  0.15954177,  0.25466388,\n",
       "        0.15314987, -0.30272555, -0.04332826, -0.04855994, -0.19888006,\n",
       "        0.1079392 ,  0.22312436, -0.1080882 , -0.34962034,  0.08483746,\n",
       "        0.16346918,  0.06331046, -0.08800558,  0.02430646, -0.4222074 ,\n",
       "        0.2652118 ,  0.2692789 ,  0.38362473, -0.4032521 ,  0.4071334 ,\n",
       "       -0.20201454,  0.09799463,  0.3336186 , -0.14650188,  0.26978266,\n",
       "        0.2910617 ,  0.00985506, -0.07141007, -0.29471913,  0.06057969,\n",
       "       -0.15602271,  0.0406785 , -0.2983785 ,  0.5999595 , -0.00488087,\n",
       "        0.03598917,  0.05591956,  0.43155602,  0.3912693 ,  0.2087107 ,\n",
       "        0.40564868,  0.06200675,  0.06451304,  0.07944345,  0.51727766,\n",
       "        0.2258708 ,  0.05465117, -0.31441158,  0.16836157, -0.02805411],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['vector'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4ab2992d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words in the vocabulary:\n",
      "['u', 'i', 'call', 'get', 'ur', 'gt', 'lt', 'go', 'free', 'know', 'got', 'like', 'good', 'ok', 'you', 'come', 'now', 'time', 'want', 'day', 'love', 'me', 'text', 'going', 'one', 'send', 'need', 'lor', 'home', 'see', 'still', 'back', 'r', 'it', 'txt', 'da', 'today', 'stop', 'think', 'reply', 'tell', 'dont', 'n', 'take', 'hi', 'new', 'sorry', 'please', 'mobile', 'phone']\n"
     ]
    }
   ],
   "source": [
    "words = word2vec_model.wv.index_to_key\n",
    "print(\"Words in the vocabulary:\")\n",
    "print(words[:50])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f421e043",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['vector']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "673adb5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d56fe8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# type of x is not a array so we need to convert it to array\n",
    "X =X.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6707392d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1e59ebb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e5b172ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "25201b6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "12f6b7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(y.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0dee4947",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d1d8f9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "177ca7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Initialize the RandomForestClassifier\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = rf_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1a777237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.965183752417795\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98       889\n",
      "           1       0.92      0.82      0.87       145\n",
      "\n",
      "    accuracy                           0.97      1034\n",
      "   macro avg       0.95      0.90      0.92      1034\n",
      "weighted avg       0.96      0.97      0.96      1034\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[879  10]\n",
      " [ 26 119]]\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Print results\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"\\nClassification Report:\\n\", report)\n",
    "print(\"\\nConfusion Matrix:\\n\", conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "59ad774c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "50cd6444",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(word2vec_model,open('word2vec.pkl','wb'))\n",
    "pickle.dump(rf_model,open('model.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9f111cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7d4f6ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Embedding, Dropout\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b9c0d810",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pad = pad_sequences(X_train, maxlen=100)\n",
    "X_test_pad = pad_sequences(X_test, maxlen=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "db2288cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(word2vec_model.wv)\n",
    "embedding_dim = word2vec_model.vector_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "bdf5ee2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3387"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "133f53d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "149ed9ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# Add the Embedding layer using pre-trained Word2Vec embeddings\n",
    "model.add(Embedding(input_dim=vocab_size, \n",
    "                    output_dim=embedding_dim, \n",
    "                    weights=[word2vec_model.wv.vectors], \n",
    "                    input_length=100,  # Set input length according to your data\n",
    "                    trainable=False))  # Keep the embeddings fixed (non-trainable)\n",
    "\n",
    "# Add LSTM layer\n",
    "model.add(LSTM(128, return_sequences=False))  # Adjust units and return_sequences based on needs\n",
    "\n",
    "# Add Dropout layer to prevent overfitting\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# Add a Dense layer for classification (binary classification)\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a12f6c19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                │ ?                           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">338,700</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                          │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)                │ ?                           │         \u001b[38;5;34m338,700\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                          │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">338,700</span> (1.29 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m338,700\u001b[0m (1.29 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">338,700</span> (1.29 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m338,700\u001b[0m (1.29 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "31103ff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 107ms/step - accuracy: 0.8537 - loss: 0.4100 - val_accuracy: 0.8598 - val_loss: 0.4062\n",
      "Epoch 2/5\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 98ms/step - accuracy: 0.8748 - loss: 0.3846 - val_accuracy: 0.8598 - val_loss: 0.4062\n",
      "Epoch 3/5\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 100ms/step - accuracy: 0.8763 - loss: 0.3786 - val_accuracy: 0.8598 - val_loss: 0.4098\n",
      "Epoch 4/5\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 126ms/step - accuracy: 0.8820 - loss: 0.3677 - val_accuracy: 0.8598 - val_loss: 0.4066\n",
      "Epoch 5/5\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 108ms/step - accuracy: 0.8753 - loss: 0.3840 - val_accuracy: 0.8598 - val_loss: 0.4116\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1f4f234f490>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=5, batch_size=32, validation_data=(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "57af281c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step\n",
      "Accuracy: 0.8597678916827853\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      1.00      0.92       889\n",
      "           1       0.00      0.00      0.00       145\n",
      "\n",
      "    accuracy                           0.86      1034\n",
      "   macro avg       0.43      0.50      0.46      1034\n",
      "weighted avg       0.74      0.86      0.79      1034\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred = (y_pred > 0.5).astype(int)  # Convert probabilities to binary values\n",
    "\n",
    "# Evaluate accuracy and print classification report\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"\\nClassification Report:\\n\", report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "91c4dcb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save('lstm_spam_model.h5')  # Save the trained LSTM model\n",
    "\n",
    "# Optionally save the Word2Vec model for later use\n",
    "pickle.dump(word2vec_model, open('word2vec_model.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee5dcd9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
